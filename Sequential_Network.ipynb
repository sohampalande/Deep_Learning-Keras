{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequential_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sohampalande/Sequential_Models_Deeplearn/blob/master/Sequential_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bBn38jAp_mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Required Libraries\n",
        "import keras\n",
        "from keras import backend as k\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "import numpy as np\n",
        "from random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "059dAaVpl8mL",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akaSqHyjgr4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels=[]\n",
        "train_samples=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p5qAzP0gtf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create Artificial Data\n",
        "\n",
        "for i in range(50):\n",
        "  random_younger=randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(1)\n",
        "  \n",
        "  random_older=randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(0)\n",
        "  \n",
        "for i in range(1000):\n",
        "  random_younger=randint(13,64)\n",
        "  train_samples.append(random_younger)\n",
        "  train_labels.append(0)\n",
        "  \n",
        "  random_older = randint(65,100)\n",
        "  train_samples.append(random_older)\n",
        "  train_labels.append(1)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FU4VrGPgv3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Processing the Data\n",
        "#Keras requires the labels to be a numpy array and the samples to be a numpy array or a list of numpy arrays\n",
        "\n",
        "train_labels=np.array(train_labels)\n",
        "train_samples=np.array(train_samples)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soclVSRUgyFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scale the Data so the Neural Network Can learn/perform better \n",
        "#Perform feature scaling using scikitlearn's scaler class MinMaxScaler\n",
        "\n",
        "#instantiate a scaler variable \n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "#scale the samples using the scaler \n",
        "scaled_train_samples=scaler.fit_transform((train_samples).reshape(-1,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_ys32al4Yo",
        "colab_type": "text"
      },
      "source": [
        "**Building the Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq-lf5VItA05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create model\n",
        "#the sequential model is a linear stack of layers (of the neural network)\n",
        "#each element of the array is a layer of the network/ can also be done using model.add()\n",
        "model=Sequential([\n",
        "    Dense(16, input_shape=(1,), activation='relu'),  #input layer\n",
        "    Dense(32, activation='relu'),                    #hidden layer\n",
        "    Dense(2, activation='softmax')                   #output layer  2 units because our data is labeled with two labels so the output can be any one of these\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IImq_9BhwzxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCnCqQFrw3U8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fede7391-743d-4c72-c4f7-a63d2ea1a442"
      },
      "source": [
        "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  \n",
        "\"\"\"the parameter 'Adam' is the optimization function for the cost/loss function that you want to use ex: gradient descent, stochastic gradient descent...\n",
        "the loss function being used is the sparse_categorical_crossentropy (other example: mean squared error cost function) and the learning rate is 0.0001\"\"\"\n",
        "#metrics evaluates the performance of the model based on accuracy\n",
        "\n",
        "    "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the parameter 'Adam' is the optimization function for the cost/loss function that you want to use ex: gradient descent, stochastic gradient descent...\\nthe loss function being used is the sparse_categorical_crossentropy (other example: mean squared error cost function) and the learning rate is 0.0001\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yup-UEszzgqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#after compiling, we train the model on the preprocessed data\n",
        "#batch size: instead of looking at each sample one by one the model analyses the samples in batches\n",
        "#EPOCH is the run thorugh the data -> the number of training runs through the data\n",
        "#shuffle : the data that the model will iterate over in each training run(EPOCH) will be in a different order default is true\n",
        "#ex : during gradient descent the model might converge to values of weights that are not the most optimum(so shuffling can address this).\n",
        "#verbose=how much output for each run of the model training \n",
        "#vallidation_split the function will split 0.1 or 10% of the data as the validation set for every traning run (epoch)\n",
        "model.fit(scaled_train_samples, train_labels,validation_split=0.1, batch_size=10, epochs=20, shuffle='true', verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usEyOoSIhVV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating a Validation Set\n",
        "#Don't train on validation set, use it only to \"validate\" the model on unseen data\n",
        "#The model will predict on the validation set during each traning run (epoch). We will see the loss and accuracy for the validation set as well\n",
        "#prevents overfitting \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mgTkK45luqY",
        "colab_type": "text"
      },
      "source": [
        "**Making** **Predictions**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajseOiIJl0Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To make predictions, we need test data/test set. (We have a training set and a cross-validation set )\n",
        "test_samples=[]\n",
        "test_labels=[]\n",
        "\n",
        "#Create artfical test data\n",
        "for i in range(50):\n",
        "  random_younger=randint(13,64)\n",
        "  test_samples.append(random_younger)\n",
        "  test_labels.append(1)\n",
        "  \n",
        "  random_older=randint(65,100)\n",
        "  test_samples.append(random_older)\n",
        "  test_labels.append(0)\n",
        "  \n",
        "for i in range(1000):\n",
        "  random_younger=randint(13,64)\n",
        "  test_samples.append(random_younger)\n",
        "  test_labels.append(0)\n",
        "  \n",
        "  random_older = randint(65,100)\n",
        "  test_samples.append(random_older)\n",
        "  test_labels.append(1)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPlA1J17nNTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert label data and sample data into numpy arrays\n",
        "test_labels=np.array(test_labels)\n",
        "test_samples=np.array(test_samples)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSFUnt6vnexM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scale the data\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "scaled_test_samples=scaler.fit_transform((test_samples).reshape(-1,1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN-BmAT-n2B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Predict\n",
        "#use the predict function to make the predictions\n",
        "#model is the variable model that refers to the model we trained in the above steps\n",
        "predictions=model.predict(scaled_test_samples, batch_size=10, verbose=0)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdDFeS0RoMB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the predictions are the probabilities of the data being a 0 or 1 - hence each row adds up to one.\n",
        "#we can round the predictions\n",
        "for i in predictions:\n",
        "  print(i)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNiWHUlQpFFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the model rounds the predictions and gives the prediction as a class (0,1)\n",
        "rounded_predictions=model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyu7hJPtqFPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in rounded_predictions:\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02zzkc1oqhvl",
        "colab_type": "text"
      },
      "source": [
        "**Evaluating the Predictions Against Our Labels Using a Confusion Matrix** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-79lscqv75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#allows us to plot within the notebook\n",
        "%matplotlib inline     \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "#a confusion matrix allows you to evaluate the performance of a classification model when the true values of the test data are known"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSPIPAv-yWya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm=confusion_matrix(test_labels, rounded_predictions)\n",
        "#plot function from sklern website\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks=np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    if normalize:\n",
        "      cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
        "      print(\"Normalized confusion Matrix\")\n",
        "    else :\n",
        "      print(\"Confusion Matrix, without Normalization\")\n",
        "      \n",
        "      print(cm)\n",
        "      thresh=cm.max()/2\n",
        "      for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i,j]),\n",
        "        horizontalalignment=\"center\"\n",
        "        color=\"white\" if cm[i,j]> thresh else \"black\"\n",
        "            \n",
        "      plt.tight_layout()\n",
        "      plt.ylabel('True Label')\n",
        "      plt.xlabel('Predicted Label')\n",
        "      \n",
        "      \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REoXfRGw0VG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "dcce0630-af47-48d3-947a-dfba4b6882fc"
      },
      "source": [
        "cm_plot_labels=['no_side_efects','side_effects']\n",
        "plot_confusion_matrix(cm,cm_plot_labels, title='Confusion Matrix')\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix, without Normalization\n",
            "[[ 943  107]\n",
            " [  46 1004]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEmCAYAAABcYEo9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYeJfDjBQCJq",
        "colab_type": "text"
      },
      "source": [
        "**Save and Load Keras Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9CqRBbcQBTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save\n",
        "model.save('medical_trial.h5') \n",
        "#use a .h5 file extension for the file location \n",
        "#if no path is passed then the model is saved to the current directory\n",
        "#preserves: the architecture of the model, the weights of the model, the cost function, optimizer function and learning rate, and \n",
        "#state of the optimizer which allows it to begin traning where it left off"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n_WFWNsRV5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load new model\n",
        "from keras.models import load_model\n",
        "new_model=load_model('medical_trial.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9G6NSonTLrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7d251a7b-dc58-4534-e4db-8708de630e82"
      },
      "source": [
        "new_model.summary()   #the model is the same as the original model"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 16)                32        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 642\n",
            "Trainable params: 642\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oemXUK4TZOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}